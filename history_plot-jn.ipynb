{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception_1.json\n",
      "dict_keys(['seg_loss', 'seg_acc', 'seg_f1', 'seg_rec', 'seg_prec', 'val_loss_PA', 'val_acc_PA', 'val_f1_PA', 'val_rec_PA', 'val_prec_PA'])\n",
      "length: 36\n",
      "max: 40.61448849463521\n",
      "position: 25\n",
      "max postion 40.61448849463521\n"
     ]
    }
   ],
   "source": [
    "# new, for deforestation\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "its = 0\n",
    "epochs = 50\n",
    "\n",
    "path = 'xception_1.json'\n",
    "model = path.split('-')[0]\n",
    "# domain = model\n",
    "print(model)\n",
    "\n",
    "history = json.load(open(path, 'r'))\n",
    "print(history.keys())\n",
    "# print(len(history['val_loss_tgt']))\n",
    "# print('max: '+ str(np.max(history['val_acc_tgt'])))\n",
    "# print('media: '+ str(sum(history['val_acc_tgt'])/len(history['val_acc_tgt'])))\n",
    "\n",
    "#dict_keys(['seg_loss', 'seg_acc', 'val_loss_RO', 'val_acc_RO',\n",
    "# 'val_f1_RO', 'val_rec_RO', 'val_prec_RO', 'val_loss_PA', 'val_acc_PA', \n",
    "# 'val_f1_PA', 'val_rec_PA', 'val_prec_PA'])\n",
    "\n",
    "print('length:', len(history[\"val_f1_PA\"]))\n",
    "print('max:', np.max(history[\"val_f1_PA\"]))\n",
    "print('position:', np.argmax(history[\"val_f1_PA\"]))\n",
    "print('max postion', history[\"val_f1_PA\"][np.argmax(history[\"val_f1_PA\"])])\n",
    "\n",
    "its = len(history['seg_acc'])//epochs\n",
    "\n",
    "\n",
    "source = 'PA'\n",
    "target = 'RO'\n",
    "source_name = 'Amazonia-PA'\n",
    "target_name = 'Amazonia-RO'\n",
    "\n",
    "\n",
    "\n",
    "# val_acc = False\n",
    "# val_loss = False\n",
    "# seg_acc_loss = False\n",
    "cyclegan_loss = False\n",
    "adv_loss = False\n",
    "gen_total = False\n",
    "\n",
    "train = False\n",
    "validation = False\n",
    "\n",
    "train_metrics = ['acc','loss','f1', 'rec', 'prec']\n",
    "# train_metrics = ['acc']\n",
    "# train_metrics = ['loss']\n",
    "# train_metrics = ['f1']\n",
    "# train_metrics = ['rec']\n",
    "# train_metrics = ['prec']\n",
    "\n",
    "validation_metrics = ['acc','loss','f1', 'rec', 'prec']\n",
    "# validation_metrics = ['acc']\n",
    "# validation_metrics = ['loss']\n",
    "# validation_metrics = ['f1']\n",
    "# validation_metrics = ['rec']\n",
    "# validation_metrics = ['prec']\n",
    "\n",
    "def tr_metrics(metric, domain, domain_name):\n",
    "    out = []\n",
    "    for i in range(len(history['seg_' + metric])//its):\n",
    "        value = np.mean(history['seg_' + metric][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "#     plt.plot(history['seg_acc'][::250])\n",
    "    plt.xlabel('epoch')\n",
    "#     plt.ylim(0,0.005)\n",
    "#     plt.xlim(10,50)\n",
    "    plt.title(domain_name + ' - Train ' + metric)\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([source_name])\n",
    "    plt.savefig(model + '-seg-' + metric + '-mean.png')\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "if train:\n",
    "    for metric in train_metrics:\n",
    "        tr_metrics(metric, source, source_name)\n",
    "\n",
    "def val_metrics(metric, domain, domain_name, sourceAndTarget = False):\n",
    "    plt.plot(history['val_' + metric + '_' + domain])\n",
    "    if sourceAndTarget:\n",
    "        plt.plot(history['val_' + metric + '_' + target])\n",
    "    plt.title(model + ' - Validation'+ ' ' + metric)\n",
    "#     plt.ylim(0,4.5)\n",
    "#     plt.xlim(0,150)\n",
    "#     plt.xlim(0,20)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('epoch')\n",
    "    if sourceAndTarget:\n",
    "        plt.legend([domain_name, target_name])\n",
    "        plt.savefig(model + '-' + metric + '.png')\n",
    "    else:\n",
    "        plt.legend([domain_name])\n",
    "        plt.savefig(model + '-' + domain + '-'+ metric + '.png')\n",
    "    \n",
    "#     plt.savefig(model + '-loss.pdf')\n",
    "    plt.clf()\n",
    "\n",
    "if validation:\n",
    "    for metric in validation_metrics:\n",
    "        val_metrics(metric, source, source_name, sourceAndTarget = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./graphs/CG_Adversarial created\n",
      "CG_Adversarial\n",
      "dict_keys(['DA_loss', 'DB_loss', 'D_loss', 'gA_d_loss_synthetic', 'gB_d_loss_synthetic', 'reconstruction_loss_A', 'reconstruction_loss_B', 'reconstruction_loss', 'GA_identity_loss', 'GB_identity_loss', 'GA_loss', 'GB_loss', 'G_loss'])\n",
      "epochs: 300\n",
      "iterations per epoch: 600\n",
      "source (A2B): PA\n",
      "target (B2A): RO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# new, for deforestation\n",
    "# for cyclegan\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "its = 0\n",
    "\n",
    "# epochs = 130\n",
    "# path = './tmp/new_test_cycle_130epoc_5_batch5_weight03_identity/models/cyclegan/history.json'\n",
    "# model = 'G256E130'\n",
    "\n",
    "epochs = 401\n",
    "path = './tmp/new_test_cycle64_400epoc_10_batch20_weight03_identity/models/cyclegan/history.json'\n",
    "model = 'G64E401-2'\n",
    "\n",
    "epochs = 300\n",
    "path = './tmp/CG_Adversarial/models/cyclegan/history.json'\n",
    "model = 'CG_Adversarial'\n",
    "\n",
    "\n",
    "output_path = os.path.join('./graphs' , model)\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "print(output_path , \"created\")\n",
    "# model = path.split('-')[0]\n",
    "# domain = model\n",
    "print(model)\n",
    "\n",
    "history = json.load(open(path, 'r'))\n",
    "print(history.keys())\n",
    "# print(len(history['val_loss_tgt']))\n",
    "# print('max: '+ str(np.max(history['val_acc_tgt'])))\n",
    "# print('media: '+ str(sum(history['val_acc_tgt'])/len(history['val_acc_tgt'])))\n",
    "\n",
    "#dict_keys(['seg_loss', 'seg_acc', 'val_loss_RO', 'val_acc_RO',\n",
    "# 'val_f1_RO', 'val_rec_RO', 'val_prec_RO', 'val_loss_PA', 'val_acc_PA', \n",
    "# 'val_f1_PA', 'val_rec_PA', 'val_prec_PA'])\n",
    "\n",
    "# print('length:', len(history[\"val_f1_PA\"]))\n",
    "# print('max:', np.max(history[\"val_f1_PA\"]))\n",
    "# print('position:', np.argmax(history[\"val_f1_PA\"]))\n",
    "# print('max postion', history[\"val_f1_PA\"][np.argmax(history[\"val_f1_PA\"])])\n",
    "\n",
    "its = len(history['DA_loss'])//epochs\n",
    "print(\"epochs:\", epochs)\n",
    "print(\"iterations per epoch:\", its)\n",
    "\n",
    "\n",
    "source = 'PA'\n",
    "target = 'RO'\n",
    "source_name = 'Amazonia-PA'\n",
    "target_name = 'Amazonia-RO'\n",
    "\n",
    "print(\"source (A2B):\", source)\n",
    "print(\"target (B2A):\", target)\n",
    "\n",
    "\n",
    "\n",
    "# val_acc = False\n",
    "# val_loss = False\n",
    "# seg_acc_loss = False\n",
    "cyclegan_loss = True\n",
    "adv_loss = True\n",
    "gen_total = True\n",
    "\n",
    "# train = False\n",
    "# train_metrics = ['seg_loss', 'seg_acc'\n",
    "#                  'DA_loss', 'DB_loss', \n",
    "#                  'gA_d_loss_synthetic', 'gB_d_loss_synthetic', \n",
    "#                  'reconstruction_loss_A', 'reconstruction_loss_B', \n",
    "#                  'GA_loss', 'GA_loss', \n",
    "#                  'GA_identity_loss', 'GB_identity_loss']\n",
    "\n",
    "\n",
    "    \n",
    "if adv_loss:\n",
    "    domain = path.split('.')[0]\n",
    "    \n",
    "    # descriminator loss\n",
    "    out = []\n",
    "    for i in range(len(history['DA_loss'])//its):\n",
    "        value = np.mean(history['DA_loss'][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "    \n",
    "    out = []\n",
    "    for i in range(len(history['DB_loss'])//its):\n",
    "        value = np.mean(history['DB_loss'][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "    \n",
    "    \n",
    "    ## general discriminator loss\n",
    "#     out = []\n",
    "#     for i in range(len(history['D_loss'])//its):\n",
    "#         value = np.mean(history['D_loss'][its*i : its*(i+1)])\n",
    "#         out.append(value)\n",
    "#     plt.plot(out)\n",
    "    \n",
    "#     plt.ylim(0,0.0003)\n",
    "#     plt.xlim(0,0.1)\n",
    "    \n",
    "    plt.title('Descriminator Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['DA_loss', 'DB_loss', 'D_loss'])\n",
    "    plt.savefig(os.path.join(output_path, domain + '-D_loss.png'))\n",
    "    plt.clf()\n",
    "    ##\n",
    "    #\n",
    "    \n",
    "    \n",
    "    # GAN loss for adversarial train\n",
    "    out = []\n",
    "    for i in range(len(history['gA_d_loss_synthetic'])//its):\n",
    "        value = np.mean(history['gA_d_loss_synthetic'][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "    \n",
    "    out = []\n",
    "    for i in range(len(history['gB_d_loss_synthetic'])//its):\n",
    "        value = np.mean(history['gB_d_loss_synthetic'][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "\n",
    "#     plt.ylim(0.999, 1.002)\n",
    "#     plt.xlim(0, 1.0)\n",
    "    \n",
    "    plt.title('Generator Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['GA_loss', 'GB_loss'])\n",
    "    plt.savefig(os.path.join(output_path, domain + '-gen-loss.png'))\n",
    "    plt.clf()\n",
    "    ##\n",
    "    #\n",
    "    \n",
    "    \n",
    "    \n",
    "if cyclegan_loss:\n",
    "    domain = path.split('.')[0]\n",
    "    \n",
    "    # Loss of image reconstruction (Gt->s(Gs->t(S)))\n",
    "    out = []\n",
    "    for i in range(len(history['reconstruction_loss_A'])//its):\n",
    "        value = np.mean(history['reconstruction_loss_A'][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "    \n",
    "    out = []\n",
    "    for i in range(len(history['reconstruction_loss_B'])//its):\n",
    "        value = np.mean(history['reconstruction_loss_B'][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "    \n",
    "    ## general rec loss\n",
    "#     out = []\n",
    "#     for i in range(len(history['reconstruction_loss'])//its):\n",
    "#         value = np.mean(history['reconstruction_loss'][its*i : its*(i+1)])\n",
    "#         out.append(value)\n",
    "#     plt.plot(out)    \n",
    "    \n",
    "#     plt.ylim(0.8, 2.0)\n",
    "#     plt.xlim(0, 1.0)\n",
    "    \n",
    "    plt.title('Reconstruction Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['reconstruction_A', 'reconstruction_B'])\n",
    "    plt.savefig(os.path.join(output_path , domain + '-rec-loss.png'))\n",
    "#     plt.savefig(os.path.join(output_path, domain + '-rec-loss.pdf'))\n",
    "    plt.clf()\n",
    "    ##\n",
    "    #\n",
    "    \n",
    "    \n",
    "    # Sum of all losses for each generator (GAN loss, identity and recosntruction)\n",
    "    out = []\n",
    "    for i in range(len(history['GA_loss'])//its):\n",
    "        value = np.mean(history['GA_loss'][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "    \n",
    "    out = []\n",
    "    for i in range(len(history['GB_loss'])//its):\n",
    "        value = np.mean(history['GB_loss'][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "    \n",
    "    ## general GAN loss\n",
    "#     out = []\n",
    "#     for i in range(len(history['G_loss'])//its):\n",
    "#         value = np.mean(history['G_loss'][its*i : its*(i+1)])\n",
    "#         out.append(value)\n",
    "#     plt.plot(out)\n",
    "    \n",
    "#     plt.ylim(1.9, 4.0)   \n",
    "#     plt.xlim(1.1, 1.9)\n",
    "\n",
    "    plt.title('CycleGAN Loss ')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Target', 'Source'])\n",
    "    plt.savefig(os.path.join(output_path, domain + '-Gen_ALLloss.png'))\n",
    "    plt.clf()\n",
    "    ##\n",
    "    #\n",
    "    \n",
    "    \n",
    "    # Identity Loss\n",
    "    out = []\n",
    "    for i in range(len(history['GA_identity_loss'])//its):\n",
    "        value = np.mean(history['GA_identity_loss'][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "    \n",
    "    out = []\n",
    "    for i in range(len(history['GB_identity_loss'])//its):\n",
    "        value = np.mean(history['GB_identity_loss'][its*i : its*(i+1)])\n",
    "        out.append(value)\n",
    "    plt.plot(out)\n",
    "    \n",
    "#     plt.ylim(0.075, 0.20)\n",
    "#     plt.xlim(0.2,1.0)\n",
    "    \n",
    "    plt.title('Identity Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['GA', 'GB'])\n",
    "    plt.savefig(os.path.join(output_path, domain + '-identity_loss.png'))\n",
    "#     plt.savefig(os.path.join(output_path, domain + '-identity_loss.pdf'))\n",
    "    plt.clf()\n",
    "    ##\n",
    "    #\n",
    "    \n",
    "    \n",
    "    # Task Loss\n",
    "    if 'seg_loss' in history:\n",
    "        out = []\n",
    "        for i in range(len(history['seg_loss'])//its):\n",
    "            value = np.mean(history['seg_loss'][its*i : its*(i+1)])\n",
    "            out.append(value)\n",
    "        plt.plot(out)\n",
    "\n",
    "#         plt.ylim(0.0, 0.003)\n",
    "    #     plt.xlim(1.1, 1.9)\n",
    "\n",
    "        plt.title(domain + ' Task Loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "    #     plt.legend(['loss'])\n",
    "        plt.savefig(os.path.join(output_path, domain + '-seg-loss.png'))\n",
    "    #     plt.savefig(os.path.join(output_path, domain + '-seg-acc-loss.pdf'))\n",
    "        plt.clf()\n",
    "        ##\n",
    "        #\n",
    "\n",
    "    \n",
    "    # Segemantation Accuracy\n",
    "    if 'seg_acc' in history:\n",
    "        out = []\n",
    "        for i in range(len(history['seg_acc'])//its):\n",
    "            value = np.mean(history['seg_acc'][its*i : its*(i+1)])\n",
    "            out.append(value)\n",
    "        plt.plot(out)\n",
    "\n",
    "#         plt.ylim(0.8, 1.0)\n",
    "#         plt.xlim(1.1, 1.9)\n",
    "\n",
    "        plt.title(domain + ' Segmentation Accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "#         plt.legend(['loss'])\n",
    "        plt.savefig(os.path.join(output_path, domain + '-seg-acc.png'))\n",
    "        plt.clf()\n",
    "        ##\n",
    "        #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
